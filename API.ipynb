{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmBfnx/gqcOrTGvg09KFvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sof1a03/KDE-group6/blob/main/API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9PHs6IFqaRV",
        "outputId": "d62220eb-1573-4735-bc2e-2b6d28f2c63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pykeen\n",
            "  Downloading pykeen-1.11.0-py3-none-any.whl.metadata (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.10.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Collecting isodate<1.0.0,>=0.7.2 (from rdflib)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.2.1)\n",
            "Collecting dataclasses-json (from pykeen)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.13.1)\n",
            "Collecting click-default-group (from pykeen)\n",
            "  Downloading click_default_group-1.2.4-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pykeen) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pykeen) (2.32.3)\n",
            "Collecting optuna>=2.0.0 (from pykeen)\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.9.0)\n",
            "Collecting more-click (from pykeen)\n",
            "  Downloading more_click-0.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from pykeen) (10.5.0)\n",
            "Collecting pystow>=0.4.3 (from pykeen)\n",
            "  Downloading pystow-0.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting docdata (from pykeen)\n",
            "  Downloading docdata-0.0.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting class-resolver>=0.5.1 (from pykeen)\n",
            "  Downloading class_resolver-0.5.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pykeen) (6.0.2)\n",
            "Collecting torch-max-mem>=0.1.1 (from pykeen)\n",
            "  Downloading torch_max_mem-0.1.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting torch-ppr>=0.0.7 (from pykeen)\n",
            "  Downloading torch_ppr-0.0.8-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=2.0.0->pykeen)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna>=2.0.0->pykeen)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (2.0.36)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->pykeen)\n",
            "  Downloading marshmallow-3.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->pykeen)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pykeen) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pykeen) (3.5.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=2.0.0->pykeen)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna>=2.0.0->pykeen) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.1.2-py3-none-any.whl (567 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.0/567.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pykeen-1.11.0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.4/718.4 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading class_resolver-0.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pystow-0.6.1-py3-none-any.whl (38 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_max_mem-0.1.3-py3-none-any.whl (10 kB)\n",
            "Downloading torch_ppr-0.0.8-py3-none-any.whl (12 kB)\n",
            "Downloading click_default_group-1.2.4-py2.py3-none-any.whl (4.1 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading docdata-0.0.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\n",
            "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, mypy-extensions, more-click, marshmallow, Mako, isodate, docdata, colorlog, click-default-group, class-resolver, typing-inspect, starlette, rdflib, pystow, alembic, torch-max-mem, optuna, fastapi, dataclasses-json, torch-ppr, pykeen\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 class-resolver-0.5.4 click-default-group-1.2.4 colorlog-6.9.0 dataclasses-json-0.6.7 docdata-0.0.4 fastapi-0.115.6 isodate-0.7.2 marshmallow-3.25.0 more-click-0.1.2 mypy-extensions-1.0.0 optuna-4.1.0 pykeen-1.11.0 pystow-0.6.1 rdflib-7.1.2 starlette-0.41.3 torch-max-mem-0.1.3 torch-ppr-0.0.8 typing-inspect-0.9.0 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "%pip install fastapi uvicorn rdflib pykeen torch numpy pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview\n",
        "**Components**\n",
        "- External Database (GraphDB): Hosts your RDF data (books, users, categories, etc.). Communicates via SPARQL queries through a RESTful endpoint.\n",
        "- API Server (FastAPI):Acts as the middleware between the database and the front-end. Processes client requests and interacts with GraphDB to fetch or manipulate data.\n",
        "- Front-End: Sends requests to the API and displays results to the user (e.g., recommendations, search results).\n",
        "- Variables and Connections:\n",
        "  - SPARQL Endpoint: The GraphDB endpoint URL for querying the database.\n",
        "  - RDF Schema: Defines relationships such as:\n",
        "      - \\<User\\> \\<likesBook\\> \\<Book\\>.  \n",
        "      - \\<Book\\> \\<hasCategory\\> \"Fiction\".\n",
        "      - \\<Book\\> \\<hasTitle\\> \"Book Title\".\n",
        "  - API Endpoints:\n",
        "  /recommended_books, /similar_books, /search, /like_book.\n",
        "  - Environment Variables: SPARQL endpoint URL. Pagination defaults (e.g., DEFAULT_PAGE_SIZE)."
      ],
      "metadata": {
        "id": "qcLcT6xkrfPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High-Level Workflow\n",
        "- **Search Functionality**:Front-end sends a search request with filters.\n",
        "API translates the request into a SPARQL query.GraphDB returns the results as RDF triples.\n",
        "- **Recommendations:** Front-end requests similar books or user-specific recommendations. API sends SPARQL queries to fetch related books or compute recommendations using precomputed relationships in GraphDB.\n",
        "- **User Actions** (like books): API sends SPARQL INSERT queries to add user preferences into GraphDB.\n",
        "- **Pagination**: API handles pageSize and pageNum by adding LIMIT and OFFSET to SPARQL queries."
      ],
      "metadata": {
        "id": "1PxbQ-JtsWtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, HTTPException, Query\n",
        "from typing import List, Optional\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "from pykeen.triples import TriplesFactory\n",
        "from node2vec import Node2Vec\n",
        "import torch\n",
        "import random\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Configuration for GraphDB and file paths\n",
        "GRAPHDB_SPARQL_ENDPOINT = \" -- \" #needs to put the db endpoint\n",
        "TRANSE_MODEL_DIR = \"transe_model_output\" # Directory where the TransE model is stored\n",
        "NODE2VEC_EMBEDDINGS_PATH = \"node2vec_embeddings.vec\" # File path to Node2Vec embeddings\n",
        "DEFAULT_PAGE_SIZE = 10  # Default number of results per page for pagination"
      ],
      "metadata": {
        "id": "EYrPUBNFqea7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TransE and Node2Vec models\n",
        "transe_model = None\n",
        "node2vec_model = None\n",
        "\n",
        "# Load TransE model\n",
        "def load_transe_model():\n",
        "    \"\"\"\n",
        "    Load the pre-trained TransE model from the specified directory.\n",
        "    \"\"\"\n",
        "    global transe_model\n",
        "    model_path = f\"{TRANSE_MODEL_DIR}/trained_model.pkl\"# Path to the serialized TransE model\n",
        "    transe_model = torch.load(model_path, map_location=torch.device(\"cpu\")) # Load the model to CPU"
      ],
      "metadata": {
        "id": "DHvdaadS3FWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Node2Vec embeddings\n",
        "def load_node2vec_embeddings():\n",
        "    \"\"\"\n",
        "    Load precomputed Node2Vec embeddings as a Word2Vec model.\n",
        "    \"\"\"\n",
        "    global node2vec_model\n",
        "    # Assume embeddings are precomputed and available as a Word2Vec model\n",
        "    from gensim.models import KeyedVectors # Import KeyedVectors for Word2Vec model\n",
        "    node2vec_model = KeyedVectors.load_word2vec_format(NODE2VEC_EMBEDDINGS_PATH, binary=False) # Load embeddings"
      ],
      "metadata": {
        "id": "WVmG76Wh3OC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper to execute SPARQL queries\n",
        "def execute_sparql_query(query: str):\n",
        "    \"\"\"\n",
        "    Execute a SPARQL query against the GraphDB endpoint.\n",
        "    Args:\n",
        "        query (str): The SPARQL query string.\n",
        "    Returns:\n",
        "        dict: Parsed JSON response from GraphDB.\n",
        "    \"\"\"\n",
        "    sparql = SPARQLWrapper(GRAPHDB_SPARQL_ENDPOINT)# Initialize SPARQL wrapper with the endpoint URL\n",
        "    sparql.setQuery(query) # Set the SPARQL query\n",
        "    sparql.setReturnFormat(JSON)# Execute the query and parse the JSON response\n",
        "    try:\n",
        "        response = sparql.query().convert() # Execute the query and parse the JSON response\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"SPARQL query failed: {e}\")  # Handle errors"
      ],
      "metadata": {
        "id": "z4xDfVtx3Qj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TransE-based recommendation logic\n",
        "def predict_top_books_transe(user_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Predict the top book recommendations for a user based on TransE embeddings.\n",
        "    Args:\n",
        "        user_id (str): The ID of the user.\n",
        "        top_n (int): Number of recommendations to return.\n",
        "    Returns:\n",
        "        list: A list of recommended book IDs.\n",
        "    \"\"\"\n",
        "    if not transe_model:  # Ensure the TransE model is loaded\n",
        "        raise HTTPException(status_code=500, detail=\"TransE model not loaded\")\n",
        "\n",
        "    entity_to_id = transe_model.entity_to_id # Retrieve entity-to-ID mapping from the model\n",
        "    if user_id not in entity_to_id:  # Check if the user exists in the model\n",
        "        raise HTTPException(status_code=404, detail=f\"User {user_id} not found\")\n",
        "\n",
        "    # Get the embedding for the user\n",
        "    user_embedding = transe_model.entity_representations[0](\n",
        "        torch.tensor([entity_to_id[user_id]])\n",
        "    ).detach().numpy().squeeze()\n",
        "\n",
        "    ''' ATTENTION: I'M NOT SURE THIS PART IS CORRECT, NEED TO CHECK WITH THE TEAM'''\n",
        "    similarities = [] # List to store similarity scores\n",
        "    for entity, idx in entity_to_id.items():\n",
        "        if entity.startswith(\"http://example.org/book\"):  # Filter only books\n",
        "            entity_embedding = transe_model.entity_representations[0](\n",
        "                torch.tensor([idx])\n",
        "            ).detach().numpy().squeeze()\n",
        "            similarity = -((user_embedding - entity_embedding) ** 2).sum()\n",
        "            similarities.append((entity, similarity))\n",
        "\n",
        "    # Sort by similarity and return the top N books\n",
        "    top_books = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    return [book for book, _ in top_books]"
      ],
      "metadata": {
        "id": "Msd66dsZ3VOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Node2Vec-based similar book recommendations\n",
        "def predict_similar_books_node2vec(book_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommend books similar to a given book using Node2Vec embeddings.\n",
        "    Args:\n",
        "        book_id (str): The ID of the book.\n",
        "        top_n (int): Number of similar books to return.\n",
        "    Returns:\n",
        "        list: A list of similar book IDs.\n",
        "    \"\"\"\n",
        "    if not node2vec_model: # Ensure the Node2Vec model is loaded\n",
        "        raise HTTPException(status_code=500, detail=\"Node2Vec model not loaded\")\n",
        "\n",
        "    try:\n",
        "        similar_books = node2vec_model.most_similar(book_id, topn=top_n)\n",
        "        return [book for book, _ in similar_books] # Return only the book IDs\n",
        "    except KeyError:\n",
        "        raise HTTPException(status_code=404, detail=f\"Book ID {book_id} not found in Node2Vec embeddings\")"
      ],
      "metadata": {
        "id": "kQ9c6CC33WUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API endpoint: Fetch personalized recommendations\n",
        "@app.get(\"/api/recommended_books\")\n",
        "def recommended_books(userid: str, top_n: int = 5):\n",
        "    \"\"\"\n",
        "    Fetch personalized book recommendations for a user using TransE and demographics.\n",
        "    Args:\n",
        "        userid (str): The ID of the user.\n",
        "        top_n (int): Number of recommendations to return.\n",
        "    Returns:\n",
        "        dict: A dictionary with the user ID and recommended books.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get recommendations using TransE\n",
        "        recommendations = predict_top_books_transe(userid, top_n=top_n)\n",
        "        return {\"userid\": userid, \"recommendations\": recommendations}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "-D5BAbYxwQGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API endpoint: Fetch books similar to a given book\n",
        "@app.get(\"/api/similar_books\")\n",
        "def similar_books(bookid: str, top_n: int = 5):\n",
        "    \"\"\"\n",
        "    Fetch books similar to the given book using Node2Vec embeddings.\n",
        "    Args:\n",
        "        bookid (str): The ID of the book.\n",
        "        top_n (int): Number of similar books to return.\n",
        "    Returns:\n",
        "        dict: A dictionary with the book ID and similar books.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        recommendations = predict_similar_books_node2vec(bookid, top_n=top_n) # Get similar books\n",
        "        return {\"bookid\": bookid, \"similar_books\": recommendations}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "S6lr8rttwVV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API endpoint: Search for books\n",
        "@app.get(\"/api/search\")\n",
        "def search_books(\n",
        "    categories: Optional[List[str]] = Query(None),\n",
        "    isbn: Optional[str] = None,\n",
        "    title: Optional[str] = None,\n",
        "    author: Optional[str] = None,\n",
        "    start_year: Optional[int] = None,\n",
        "    end_year: Optional[int] = None,\n",
        "    pageSize: int = 10,\n",
        "    pageNum: int = 1,\n",
        "):\n",
        "    \"\"\"\n",
        "    Search for books by category, ISBN, title, author, or publication year.\n",
        "    Args:\n",
        "        categories (List[str], optional): List of book categories to filter.\n",
        "        isbn (str, optional): ISBN of the book.\n",
        "        title (str, optional): Title of the book.\n",
        "        author (str, optional): Author of the book.\n",
        "        start_year (int, optional): Start of the publication year range.\n",
        "        end_year (int, optional): End of the publication year range.\n",
        "        pageSize (int): Number of results per page.\n",
        "        pageNum (int): Page number to return.\n",
        "    Returns:\n",
        "        dict: A dictionary of search results.\n",
        "    \"\"\"\n",
        "    query = \"\"\"\n",
        "    SELECT ?book ?title ?author WHERE {\n",
        "        ?book <http://example.org/hasTitle> ?title .\n",
        "        OPTIONAL { ?book <http://example.org/hasAuthor> ?author . }\n",
        "    \"\"\"\n",
        "    if categories:\n",
        "        category_filter = \" || \".join([f'?category = \"{cat}\"' for cat in categories])\n",
        "        query += f\"?book <http://example.org/hasCategory> ?category . FILTER({category_filter})\"\n",
        "\n",
        "    if isbn:\n",
        "        query += f'?book <http://example.org/hasISBN> \"{isbn}\" .'\n",
        "\n",
        "    if title:\n",
        "        query += f'FILTER regex(?title, \"{title}\", \"i\") .'\n",
        "\n",
        "    if author:\n",
        "        query += f'?book <http://example.org/hasAuthor> \"{author}\" .'\n",
        "\n",
        "    if start_year:\n",
        "        query += f'?book <http://example.org/hasYear> ?year . FILTER(?year >= {start_year}) .'\n",
        "\n",
        "    if end_year:\n",
        "        query += f'?book <http://example.org/hasYear> ?year . FILTER(?year <= {end_year}) .'\n",
        "\n",
        "    query += f\"}} LIMIT {pageSize} OFFSET {(pageNum - 1) * pageSize}\" # Add pagination to the query\n",
        "\n",
        "    try:\n",
        "        results = execute_sparql_query(query) # Execute the SPARQL query\n",
        "        books = [\n",
        "        books = [\n",
        "            {\"bookid\": binding[\"book\"][\"value\"], \"title\": binding[\"title\"][\"value\"]}\n",
        "            for binding in results[\"results\"][\"bindings\"]\n",
        "        ]\n",
        "        return {\"results\": books} # Return search results\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "vN25VqfGwfB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API endpoint: Fetch random book recommendations\n",
        "\n",
        "@app.get(\"/api/surprise_me\")\n",
        "def surprise_me(userid: Optional[str] = None, top_n: int = 5):\n",
        "    \"\"\"\n",
        "    Fetch random book recommendations, excluding books already liked by the user.\n",
        "    Args:\n",
        "        userid (str, optional): The ID of the user.\n",
        "        top_n (int): Number of random books to return.\n",
        "    Returns:\n",
        "        dict: A dictionary of random book recommendations.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query = \"SELECT ?book WHERE { ?book a <http://example.org/Book> }\"\n",
        "        all_books = execute_sparql_query(query)[\"results\"][\"bindings\"]\n",
        "\n",
        "        if userid: # If a user ID is provided, exclude liked books\n",
        "            liked_query = f\"\"\"\n",
        "            SELECT ?book WHERE {{\n",
        "                <http://example.org/user/{userid}> <http://example.org/likesBook> ?book .\n",
        "            }}\n",
        "            \"\"\"\n",
        "            liked_books = execute_sparql_query(liked_query)[\"results\"][\"bindings\"]\n",
        "            liked_book_ids = {b[\"book\"][\"value\"] for b in liked_books}\n",
        "            available_books = [b[\"book\"][\"value\"] for b in all_books if b[\"book\"][\"value\"] not in liked_book_ids]\n",
        "        else:\n",
        "            available_books = [b[\"book\"][\"value\"] for b in all_books]\n",
        "\n",
        "        random.shuffle(available_books) # Shuffle books for randomness\n",
        "        return {\"surprise_me\": available_books[:top_n]} # Return random recommendations\n",
        "    except Exception as e:\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "bLDD0I79wiIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models on startup\n",
        "@app.on_event(\"startup\")\n",
        "def load_models():\n",
        "    \"\"\"\n",
        "    Load models (TransE and Node2Vec) when the application starts.\n",
        "    \"\"\"\n",
        "    load_transe_model()  # Load the TransE model\n",
        "    load_node2vec_embeddings()  # Load the Node2Vec embeddings"
      ],
      "metadata": {
        "id": "3CoZopXuwnKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}