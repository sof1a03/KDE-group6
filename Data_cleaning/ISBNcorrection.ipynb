{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sof1a03/KDE-group6/blob/main/ISBNcorrection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ftC8_50sTje"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from multiprocessing.pool import ThreadPool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qfnDxB9o4Th",
        "outputId": "2fb80332-be9e-4372-fb06-00bf858e4a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f46b15fa6211>:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books = pd.read_csv(\"Books.csv\")\n"
          ]
        }
      ],
      "source": [
        "books = pd.read_csv(\"Books.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books['ISBN'] = books['ISBN'].str.upper()"
      ],
      "metadata": {
        "id": "TNWO0bg8t7d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-iVTL7WudAQ",
        "outputId": "95ef07c0-711e-4a96-defe-d783898630bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 271360 entries, 0 to 271359\n",
            "Data columns (total 8 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   ISBN                 271360 non-null  object\n",
            " 1   Book_Title           271360 non-null  object\n",
            " 2   Book_Author          271358 non-null  object\n",
            " 3   Year_Of_Publication  271360 non-null  object\n",
            " 4   Publisher            271358 non-null  object\n",
            " 5   Image_URL_S          271360 non-null  object\n",
            " 6   Image_URL_M          271360 non-null  object\n",
            " 7   Image_URL_L          271357 non-null  object\n",
            "dtypes: object(8)\n",
            "memory usage: 16.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "!pip install graphframes\n",
        "!pip install\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XByZO3m0v1HY",
        "outputId": "90277bf0-01c9-4565-84ed-e4ed59e81b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u432-ga~us1-0ubuntu2~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u432-ga~us1-0ubuntu2~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Collecting graphframes\n",
            "  Downloading graphframes-0.6-py2.py3-none-any.whl.metadata (934 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.26.4)\n",
            "Collecting nose (from graphframes)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nose, graphframes\n",
            "Successfully installed graphframes-0.6 nose-1.3.7\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import (\n",
        "    col,\n",
        "    udf,\n",
        "    row_number,\n",
        "    countDistinct,\n",
        "    collect_list,\n",
        "    struct,\n",
        "    count,\n",
        "    sum,\n",
        "    avg,\n",
        "    expr,\n",
        "    lit,\n",
        "    percentile_approx,\n",
        "    max as spark_max,\n",
        "    explode,\n",
        "    least,\n",
        "    greatest\n",
        ")\n",
        "from pyspark.sql.types import StringType, IntegerType, BinaryType, DoubleType, ArrayType, StructType, StructField\n",
        "from pyspark.sql import Window\n",
        "from datetime import datetime\n",
        "from graphframes import GraphFrame\n",
        "from scipy.sparse import csr_matrix, vstack, hstack\n",
        "import numpy as np\n",
        "import pickle\n",
        "import base64\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "5-lQh1EM8tBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ISBNValidationandAPICheck\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.1-s_2.12\") \\\n",
        "    .config(\"spark.executor.memory\", \"20G\") \\\n",
        "    .config(\"spark.driver.memory\", \"50G\") \\\n",
        "    .config(\"spark.executor.memoryOverhead\", \"1G\") \\\n",
        "    .config(\"spark.default.parallelism\", \"100\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
        "    .getOrCreate()\n",
        "\n"
      ],
      "metadata": {
        "id": "KM7RMd2f87pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, length, when, expr, lit, sum as spark_sum\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Corrected ISBN Validation Debugged\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "books = spark.read.csv(\"Books.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Normalize ISBN column: Remove hyphens and whitespace\n",
        "books = books.withColumn(\"ISBN\", expr(\"regexp_replace(trim(ISBN), '-', '')\"))\n",
        "\n",
        "# Validate ISBN Length (10 or 13)\n",
        "books = books.withColumn(\n",
        "    \"is_valid_length\",\n",
        "    when((length(col(\"ISBN\")) == 10) | (length(col(\"ISBN\")) == 13), True).otherwise(False)\n",
        ")\n",
        "\n",
        "# Add position column (POS) for each character in ISBN\n",
        "books_with_pos = books.withColumn(\"POS\", expr(\"sequence(1, length(ISBN))\"))\n",
        "books_exploded = books_with_pos.withColumn(\"POS\", expr(\"explode(POS)\"))\n",
        "\n",
        "# Extract character values using substring\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"digit_value\",\n",
        "    when(expr(\"substring(ISBN, POS, 1)\") == \"X\", lit(10))\n",
        "    .otherwise(expr(\"CAST(substring(ISBN, POS, 1) AS INT)\"))\n",
        ")\n",
        "\n",
        "# Add weights for ISBN-10 (Corrected Formula)\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"weight_10\",\n",
        "    when(length(\"ISBN\") == 10, 11 - col(\"POS\")).otherwise(0)\n",
        ")\n",
        "\n",
        "# Add weights for ISBN-13\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"weight_13\",\n",
        "    when(length(\"ISBN\") == 13, when((col(\"POS\") % 2) == 1, 1).otherwise(3)).otherwise(0)\n",
        ")\n",
        "\n",
        "# Compute weighted contributions for ISBN-10 and ISBN-13\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"weighted_value_10\",\n",
        "    col(\"digit_value\") * col(\"weight_10\")\n",
        ").withColumn(\n",
        "    \"weighted_value_13\",\n",
        "    col(\"digit_value\") * col(\"weight_13\")\n",
        ")\n",
        "\n",
        "# Sum contributions for ISBN-10 and ISBN-13\n",
        "weighted_sum = books_exploded.groupBy(\"ISBN\").agg(\n",
        "    spark_sum(\"weighted_value_10\").alias(\"weighted_sum_10\"),\n",
        "    spark_sum(\"weighted_value_13\").alias(\"weighted_sum_13\"),\n",
        "    spark_sum(\n",
        "        when(col(\"POS\") == 10, col(\"digit_value\")).otherwise(0)\n",
        "    ).alias(\"last_digit\")\n",
        ")\n",
        "\n",
        "# Add checksum validations for ISBN-10 and ISBN-13\n",
        "weighted_sum = weighted_sum.withColumn(\n",
        "    \"checksum_valid_10\",\n",
        "    (length(col(\"ISBN\")) == 10) & (((col(\"weighted_sum_10\")) % 11) == 0)\n",
        ").withColumn(\n",
        "    \"checksum_valid_13\",\n",
        "    (length(col(\"ISBN\")) == 13) & ((col(\"weighted_sum_13\") % 10) == 0)\n",
        ")\n",
        "\n",
        "# Combine checksum validations\n",
        "weighted_sum = weighted_sum.withColumn(\n",
        "    \"Validity\",\n",
        "    when(col(\"checksum_valid_10\") | col(\"checksum_valid_13\"), \"Valid\").otherwise(\"Invalid\")\n",
        ")\n",
        "\n",
        "# Debugging: Show intermediate results for ISBN 0671002481\n",
        "debug_weights = books_exploded.filter(col(\"ISBN\") == \"0671002481\")\n",
        "debug_weights.select(\"ISBN\", \"POS\", \"digit_value\", \"weight_10\", \"weighted_value_10\").show(truncate=False)\n",
        "\n",
        "debug_sum = weighted_sum.filter(col(\"ISBN\") == \"0671002481\")\n",
        "debug_sum.select(\"ISBN\", \"weighted_sum_10\", \"last_digit\", \"checksum_valid_10\", \"Validity\").show(truncate=False)\n",
        "\n",
        "# Show all ISBNs with their validity status\n",
        "weighted_sum.select(\"ISBN\", \"Validity\").show(truncate=False)\n",
        "\n",
        "# Stop Spark Session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKEItrJLmuCa",
        "outputId": "45b7e4d1-c1a6-42d2-cc3f-0bb4e2c1bfe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+-----------+---------+-----------------+\n",
            "|ISBN      |POS|digit_value|weight_10|weighted_value_10|\n",
            "+----------+---+-----------+---------+-----------------+\n",
            "|0671002481|1  |0          |10       |0                |\n",
            "|0671002481|2  |6          |9        |54               |\n",
            "|0671002481|3  |7          |8        |56               |\n",
            "|0671002481|4  |1          |7        |7                |\n",
            "|0671002481|5  |0          |6        |0                |\n",
            "|0671002481|6  |0          |5        |0                |\n",
            "|0671002481|7  |2          |4        |8                |\n",
            "|0671002481|8  |4          |3        |12               |\n",
            "|0671002481|9  |8          |2        |16               |\n",
            "|0671002481|10 |1          |1        |1                |\n",
            "+----------+---+-----------+---------+-----------------+\n",
            "\n",
            "+----------+---------------+----------+-----------------+--------+\n",
            "|ISBN      |weighted_sum_10|last_digit|checksum_valid_10|Validity|\n",
            "+----------+---------------+----------+-----------------+--------+\n",
            "|0671002481|154            |1         |true             |Valid   |\n",
            "+----------+---------------+----------+-----------------+--------+\n",
            "\n",
            "+----------+--------+\n",
            "|ISBN      |Validity|\n",
            "+----------+--------+\n",
            "|080652121X|Valid   |\n",
            "|1558746218|Valid   |\n",
            "|0689821166|Valid   |\n",
            "|0971880107|Valid   |\n",
            "|0345402871|Valid   |\n",
            "|3442353866|Valid   |\n",
            "|067176537X|Valid   |\n",
            "|0245542957|Valid   |\n",
            "|1853262404|Valid   |\n",
            "|0345465083|Valid   |\n",
            "|0060930365|Valid   |\n",
            "|1903019699|Valid   |\n",
            "|0830714014|Valid   |\n",
            "|3257203659|Valid   |\n",
            "|3257212429|Valid   |\n",
            "|3596292646|Valid   |\n",
            "|0316602906|Valid   |\n",
            "|0316693006|Valid   |\n",
            "|0345433173|Valid   |\n",
            "|0380807866|Valid   |\n",
            "+----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, length, when, expr, lit, sum as spark_sum\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Corrected ISBN Validation Debugged\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "books = spark.read.csv(\"Books.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Normalize ISBN column: Remove hyphens and whitespace\n",
        "books = books.withColumn(\"ISBN\", expr(\"regexp_replace(trim(ISBN), '-', '')\"))\n",
        "\n",
        "# Validate ISBN Length (10 or 13)\n",
        "books = books.withColumn(\n",
        "    \"is_valid_length\",\n",
        "    when((length(col(\"ISBN\")) == 10) | (length(col(\"ISBN\")) == 13), True).otherwise(False)\n",
        ")\n",
        "\n",
        "# Add position column (POS) for each character in ISBN\n",
        "books_with_pos = books.withColumn(\"POS\", expr(\"sequence(1, length(ISBN))\"))\n",
        "books_exploded = books_with_pos.withColumn(\"POS\", expr(\"explode(POS)\"))\n",
        "\n",
        "# Extract character values using substring\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"digit_value\",\n",
        "    when(expr(\"upper(substring(ISBN, POS, 1))\") == \"X\", lit(10))\n",
        "    .otherwise(expr(\"CAST(substring(ISBN, POS, 1) AS INT)\"))\n",
        ")\n",
        "\n",
        "# Add weights for ISBN-10 (Corrected Formula)\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"weight_10\",\n",
        "    when(length(\"ISBN\") == 10, 11 - col(\"POS\")).otherwise(0)\n",
        ")\n",
        "\n",
        "# Add weights for ISBN-13\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"weight_13\",\n",
        "    when(length(\"ISBN\") == 13, when((col(\"POS\") % 2) == 1, 1).otherwise(3)).otherwise(0)\n",
        ")\n",
        "\n",
        "# Compute weighted contributions for ISBN-10 and ISBN-13\n",
        "books_exploded = books_exploded.withColumn(\n",
        "    \"weighted_value_10\",\n",
        "    col(\"digit_value\") * col(\"weight_10\")\n",
        ").withColumn(\n",
        "    \"weighted_value_13\",\n",
        "    col(\"digit_value\") * col(\"weight_13\")\n",
        ")\n",
        "\n",
        "# Sum contributions for ISBN-10 and ISBN-13\n",
        "weighted_sum = books_exploded.groupBy(\"ISBN\").agg(\n",
        "    spark_sum(\"weighted_value_10\").alias(\"weighted_sum_10\"),\n",
        "    spark_sum(\"weighted_value_13\").alias(\"weighted_sum_13\"),\n",
        "    spark_sum(\n",
        "        when(col(\"POS\") == 10, col(\"digit_value\")).otherwise(0)\n",
        "    ).alias(\"last_digit\")\n",
        ")\n",
        "\n",
        "# Add checksum validations for ISBN-10 and ISBN-13\n",
        "weighted_sum = weighted_sum.withColumn(\n",
        "    \"checksum_valid_10\",\n",
        "    (length(col(\"ISBN\")) == 10) & (((col(\"weighted_sum_10\")) % 11) == 0)\n",
        ").withColumn(\n",
        "    \"checksum_valid_13\",\n",
        "    (length(col(\"ISBN\")) == 13) & ((col(\"weighted_sum_13\") % 10) == 0)\n",
        ")\n",
        "\n",
        "# Combine checksum validations\n",
        "weighted_sum = weighted_sum.withColumn(\n",
        "    \"Validity\",\n",
        "    when(col(\"checksum_valid_10\") | col(\"checksum_valid_13\"), \"Valid\").otherwise(\"Invalid\")\n",
        ")\n",
        "\n",
        "# Join back with the original dataset to retrieve titles\n",
        "books_with_validity = books.join(weighted_sum, on=\"ISBN\", how=\"inner\")\n",
        "\n",
        "# Filter for invalid ISBNs only\n",
        "invalid_books = books_with_validity.filter(col(\"Validity\") == \"Invalid\")\n",
        "\n",
        "# Select and show ISBNs and titles of invalid books\n",
        "invalid_books.select(\"ISBN\", \"Book_Title\", \"Book_Author\").show(truncate=False)\n",
        "# Save invalid books to a CSV file\n",
        "invalid_books.write.csv(\"invalid_books.csv\", header=True, mode=\"overwrite\")\n",
        "# Stop Spark Session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXGr_xFKtjaO",
        "outputId": "66dfe3a4-817d-4029-9c60-755210cd9ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------------------------------------------------------------------+-----------------------+\n",
            "|ISBN      |Book_Title                                                                    |Book_Author            |\n",
            "+----------+------------------------------------------------------------------------------+-----------------------+\n",
            "|B0000A2U93|Carmilla                                                                      |Joseph Sheridan Le Fanu|\n",
            "|B0000633PU|The Story of Aladdin and the Wonderful Lamp                                   |S. Lane Poole          |\n",
            "|B00007FYKO|Bloodcurdling Tales of Horror and the Macabre: The Best of H. P. Lovecraft    |H. P. Lovecraft        |\n",
            "|B00008NRHQ|Mystic Rose, The                                                              |Stephen R. Lawhead     |\n",
            "|B00009ANY9|Cane River                                                                    |Lalita Tademy          |\n",
            "|B00009APKU|Moby Dick                                                                     |Herman Melville        |\n",
            "|B00005NCS7|Moonlight Becomes You                                                         |Mary Higgins Clark     |\n",
            "|B00006CRTE|Devil Knows You're Dead, The: A Matthew Scudder Crime Novel                   |Lawrence Block         |\n",
            "|B00007MF56|More, Now, Again: A Memoir of Addiction                                       |Elizabeth Wurtzel      |\n",
            "|B0000DAPP1|Discover Your Genius: How to Think Like History's Ten Most Revolutionary Minds|Michael J. Gelb        |\n",
            "|B000069F44|The Lady in the Lake                                                          |Lin Carter             |\n",
            "|B0000523SS|The Covenant of the Crown                                                     |Howard Weinstein       |\n",
            "|B000051WXP|Emma                                                                          |Jane Austen            |\n",
            "|B0001GMSV2|Find Me                                                                       |Rosie O'Donnell        |\n",
            "|B00005Q8R2|Hell's Kitchen                                                                |Jeffery Deaver         |\n",
            "|B00009NDAN|Winter Solstice                                                               |Rosamunde Pilcher      |\n",
            "|B00001U0CP|Unnatural Exposure                                                            |Patricia Cornwell      |\n",
            "|B00009EF82|Hannibal                                                                      |Thomas Harris          |\n",
            "|B00005U7YK|The New Gurus -- From Sun-Tzu And Jesus To Machiavelli And Winnie The Pooh    |Stuart Crainer         |\n",
            "|B000234N76|Falling Angels                                                                |Tracy Chevalier        |\n",
            "+----------+------------------------------------------------------------------------------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWhWYMy92VbQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvFblDvsT4jeQ8430yW1ac",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
